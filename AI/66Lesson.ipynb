{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b527adf-4b3a-4bb6-93e4-908da4642153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a910324-abc8-408b-bd5e-b62b227323d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image label: tensor([3])\n",
      "Image shape: torch.Size([1, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c977137c70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainset = datasets.MNIST('Datasets', download=True, train=True, transform=transforms.ToTensor())\n",
    "testset = datasets.MNIST('Datasets', download=True, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "trainloader = DataLoader(trainset, shuffle=True)\n",
    "testloader = DataLoader(testset, shuffle=True)\n",
    "\n",
    "image, label = iter(trainloader).next()\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9156b0d5-e9fc-4441-837e-aa42f6540e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train setlength: 60000\n",
      "Test setlength: 10000\n",
      "Ravel image size: 784\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train setlength: {len(trainset)}\")\n",
    "print(f\"Test setlength: {len(testset)}\")\n",
    "print(f\"Ravel image size: {28*28}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a5b985-b8d7-4b75-b6fe-de1698a06512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model: MNIST_Logistic_Regression(\n",
      "  (lin): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "Parameters: [Parameter containing:\n",
      "tensor([[ 0.0054,  0.0100, -0.0189,  ...,  0.0076,  0.0102,  0.0186],\n",
      "        [ 0.0224,  0.0185,  0.0310,  ...,  0.0124,  0.0020, -0.0093],\n",
      "        [-0.0106,  0.0314,  0.0300,  ...,  0.0074,  0.0268,  0.0276],\n",
      "        ...,\n",
      "        [-0.0122, -0.0184, -0.0128,  ...,  0.0024, -0.0034,  0.0285],\n",
      "        [ 0.0245, -0.0304,  0.0056,  ..., -0.0168, -0.0323,  0.0202],\n",
      "        [-0.0016, -0.0295, -0.0013,  ..., -0.0178,  0.0033,  0.0052]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0125,  0.0105, -0.0106,  0.0039,  0.0321, -0.0027,  0.0326, -0.0250,\n",
      "         0.0041, -0.0239], requires_grad=True)]\n",
      "Output shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# nn.Module\n",
    "class MNIST_Logistic_Regression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_hat = self.lin(x)\n",
    "        return y_hat\n",
    "    \n",
    "model = MNIST_Logistic_Regression()\n",
    "x_rand = torch.rand(1, 784)\n",
    "y = model(x_rand)\n",
    "\n",
    "#model = nn.Linear(784, 10)\n",
    "#x_rand = torch.rand(1, 784)\n",
    "#y = model(x_rand)\n",
    "\n",
    "print(f\"The model: {model}\")\n",
    "print(f\"Parameters: {list(model.parameters())}\")\n",
    "print(f\"Output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf5136c-484d-442e-88d1-3c9327650aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 60000/60000 [01:33<00:00, 642.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:06<00:00, 1499.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 0.9023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pip install tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = MNIST_Logistic_Regression()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001) #learning rate\n",
    "\n",
    "correct = 0\n",
    "total_train = len(trainset)\n",
    "\n",
    "for image, label in tqdm(trainloader): #TQDM\n",
    "    optimizer.zero_grad() # Очищает значения градиентов параметров\n",
    "    x = image.view(1, -1)\n",
    "    y = model(x) #y.shape = (1, 10)\n",
    "    \n",
    "    predictions = torch.argmax(y, dim=1)\n",
    "    correct += torch.sum((predictions == label).float())\n",
    "    \n",
    "    loss = criterion(y, label)    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(f\"Train set accuracy: {(correct/total_train):.4}\")\n",
    "\n",
    "correct = 0 \n",
    "total_test = len(testset)\n",
    "with torch.no_grad():\n",
    "    for image, label in tqdm(testloader):\n",
    "        x = image.view(-1, 28*28)\n",
    "        y = model(x)\n",
    "        \n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correct += torch.sum((predictions == label).float())\n",
    "print(f\"\\nTest set accuracy: {(correct/total_test):.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd60b0fb-210b-49fa-8bce-6c613960bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 60000/60000 [05:21<00:00, 186.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 0.8685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:09<00:00, 1078.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 0.8831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class MNIST_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin_1 = nn.Linear(784, 256)\n",
    "        self.lin_2 = nn.Linear(256, 64)\n",
    "        self.lin_3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        a1 = self.lin_1(x)\n",
    "        a2 = self.lin_2(a1)\n",
    "        y_hat = self.lin_3(a2)\n",
    "        return y_hat\n",
    "    \n",
    "model = MNIST_NN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "correct = 0\n",
    "total_train = len(trainset)\n",
    "\n",
    "for image, label in tqdm(trainloader): #TQDM\n",
    "    optimizer.zero_grad() # Очищает значения градиентов параметров\n",
    "    x = image.view(1, -1)\n",
    "    y = model(x) #y.shape = (1, 10)\n",
    "    \n",
    "    predictions = torch.argmax(y, dim=1)\n",
    "    correct += torch.sum((predictions == label).float())\n",
    "    \n",
    "    loss = criterion(y, label)    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(f\"Train set accuracy: {(correct/total_train):.4}\")\n",
    "\n",
    "correct = 0 \n",
    "total_test = len(testset)\n",
    "with torch.no_grad():\n",
    "    for image, label in tqdm(testloader):\n",
    "        x = image.view(-1, 28*28)\n",
    "        y = model(x)\n",
    "        \n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correct += torch.sum((predictions == label).float())\n",
    "print(f\"\\nTest set accuracy: {(correct/total_test):.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a49297-cdd7-48d4-a59b-774b5d4e4d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
